---
layout: post
title: "Backtracking line search"
comments: false
abstract: 無制約最適化のアルゴリズムの1つ
---

### はじめに

以下の本を2年前に買って手を付けていなかったので読み始めた．
無制約最適化のバックトラック法による直線探索の実装をJuliaでやった．

<a href="https://www.amazon.co.jp/%E5%9F%BA%E7%A4%8E%E7%B3%BB-%E6%95%B0%E5%AD%A6-%E6%9C%80%E9%81%A9%E5%8C%96%E3%81%A8%E5%A4%89%E5%88%86%E6%B3%95-%E6%9D%B1%E4%BA%AC%E5%A4%A7%E5%AD%A6%E5%B7%A5%E5%AD%A6%E6%95%99%E7%A8%8B-%E5%AF%92%E9%87%8E/dp/4621088548/ref=as_li_ss_il?ie=UTF8&qid=1489251585&sr=8-1&keywords=%E6%9C%80%E9%81%A9%E5%8C%96%E3%81%A8%E5%A4%89%E5%88%86%E6%B3%95&linkCode=li2&tag=algebrae-22&linkId=a79b39ec42f08d08baa9630ac20d3d39" target="_blank"><img border="0" src="//ws-fe.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=4621088548&Format=_SL160_&ID=AsinImage&MarketPlace=JP&ServiceVersion=20070822&WS=1&tag=algebrae-22" ></a><img src="https://ir-jp.amazon-adsystem.com/e/ir?t=algebrae-22&l=li2&o=9&a=4621088548" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />

ステップ幅 $$\alpha$$ をBacktracking line searchで探索する．

### コード

``` julia
function armijo(x, grad)
  f_k = obj(x)
  a = 1.
  rho = 0.5
  c = 0.001
  c_innter_prod_g = c*dot(grad, -grad)
  while obj(x-a*grad) > f_k+a*c_innter_prod_g
    a *= rho
  end
  return a
end

function gradient_descent(x)
  eps = 10.0^-2
  k = 1
  while true
    obj_grad_x = obj_grad(x)
    if norm(obj_grad_x) < eps
      break
    end
    alpha = armijo(x, obj_grad_x)
    x -= alpha*obj_grad_x
    k += 1
  end

  return x
end

function obj(x)
  x1, x2 = x
  return 0.5x1^4 - 2x1^2*x2 + 4x2^2 + 8x1 + 8x2
end

function obj_grad(x)
  x1, x2 = x
  return [2x1^3 - 4*x1*x2 + 8, -2x1^2 + 8x2 + 8]
end

x = [3., 1.]
println(gradient_descent(x))
```

解がテキストとほぼ一致しているので，可視化してみる．右上の $$(3, 1)$$ が初期値．
テキストと異なるパラメータを使っているらしく，ステップ幅がだいぶ大きくなっているが，収束している．

![to_opt_x]({{ site.url }}/images/armijo.png)
