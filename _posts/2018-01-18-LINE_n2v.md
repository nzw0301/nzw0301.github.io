---
layout: post
title: "LINEとn2vをフェアに比較したい"
comments: false
---

実験はしてません．

### 背景

グラフでも分散表現 (Skip-gram with negative sampling) みたいなのが流行りまくっています [[^1]]．
古典的なグラフスペクトラルを行列分解するみたいなやつを除くと

- [DeepWalk](http://www.perozzi.net/projects/deepwalk/)
- [LINE](http://nzw0301.github.io/2017/01/LINE)
- [node2vec](http://nzw0301.github.io/2016/07/node2vec)

の3つがベースラインでよく使われます．
ただし，DeepWalkとnode2vecは，ほぼ一緒なので片方で十分だと思っています．
今回は後者だけを使いたいとします．

node2vecは公式実装が2つあり，[python or Spark](https://github.com/aditya-grover/node2vec)と[C++](https://github.com/snap-stanford/snap/tree/master/examples/node2vec)です．
前者と後者でsub-samplingするしないの違いとかいろいろあるんですが，速い後者を考えます．

本記事と似たような議論が[node2vec論文](http://www.kdd.org/kdd2016/papers/files/rfp0218-groverA.pdf)でもあります，ただ読んだ感じ，実装とは違う印象です．

---

### 本題

まず，何をフェアにしたいかですが，幸いなことにLINEもnode2vecもSkip-gram with negative samplingとかなり似ています．
というわけでskip-gram with negative samplingで更新する単語数をだいたい一緒にしようと考えます．

#### [LINE](https://github.com/tangjianpku/LINE)

LINEではエッジをサンプルし，それを正例とします．
いくつエッジをサンプルするかは，グラフの大きさに依存せず，コマンドラインの引数の `-samples` * `Million` だけサンプルします．
`-samples`のデフォルト値は， `1` です．
なので，小規模グラフでは`1`でいいのですが，大規模グラフだとよくありません．

negative samplingの数はコマンドライン引数で変更できます．
デフォルトは `5` です．

ちなみに，LINEの問題点として低次数ノードの訓練が上手くいかないというものがあり，擬似的にエッジを生やすコードがあるのですが，試したらひどいことになったので，[Issue](https://github.com/tangjianpku/LINE/issues/21)のように再現するようなら使わないほうがいいと思います．

---

#### [node2vec](https://github.com/snap-stanford/snap/tree/master/examples/node2vec)

node2vecでは，グラフ上でランダムウォークを行い，それをコーパスとみなしてskip-gram with negative samplingします．
ただし，C++実装では，sub-samplingはしません．
python実装ではgensimを継承してるのでおそらくsub-samplingします．

今回は，skip-gramを扱うわけなので，ランダムウォークで作ったコーパスに含まれるノード数をLINEの`-samples`と一緒にするとLINEが不利になるため，少し計算していきます．

node2vecの正例の数に関係するのは，以下のパラメータです．

- `r`: 1ノードを始点としたときのランダムウォークの回数．デフォルト`10`．
- `l`: ランダムウォークの長さ．デフォルト`80`．
- `k`: 文脈窓幅．デフォルト`10`．
- `e`: SGDの反復回数．デフォルト`1`．

素直に考えると扱う正例数は

$$r \times l \times 2k \times e$$

です．
注意点として `k` は片側に対する値なので，2倍します．
ただ，これだと多めです．

まず窓幅ですが，乱数に依存しており，これはword2vec実装と同様に最大値が `k` であり，最小値が `1` です [[^2]]．
なので期待値を取る必要があります．
例えば，`k=10` とするなら

$$\frac{1}{10} \sum_{i=1}^{10} 2i = 11$$

です．
よって $$2 \times k$$ ではなくて $$\frac{2}{k} \frac{k(k+1)}{2}=k+1$$ です．

$$r \times l \times (k+1) \times e$$

残念ながら，厳密には，これでもまだ多めな見積もりです．
例えば，ランダムウォークの先頭のノードを処理する場合は，さきほど求めた期待値は更に小さくなります．

`[0, 1, 2, 3, 4, ..., 79] # l=80`

を考えると`0`を軸として扱う場合は，左側にはノードがないので，期待値も減ります．
ここでは話がややこしくなるのを避けて，`l>2k, k=10`のときで具体例を考えてみます．

- 軸`0`: $$\frac{10(10+1)}{2 \times 10}=5.5$$
- 軸`1`: $$\frac{9(9+1)}{2 \times 10}=4.5$$
- ...
- 軸`9`: $$\frac{1(1+1)}{2 \times 10}=0.1$$

というわけで
軸の位置を`c`とするなら，$$\frac{(k-c)((k-c)+1)}{2 \times k}$$です．
右側も同様に計算するので，

$$\sum_{c=0}^{k} 2 \frac{(k-c)((k-c)+1)}{2 \times k} = \sum_{c=0}^{k} \frac{(k-c)((k-c)+1)}{k} = R$$

回のノード対の更新が1ランダムウォークあたりに減ります．

以上より，node2vecでは，

$$r \times ((l \times (k+1)) - (l \times R)) \times e$$

回だけ正例を処理します．
この値がLINEの`-samples`Mと同じくらいだとフェアといえそうです．

negative samplingの個数は固定されており，[個数は5](https://github.com/snap-stanford/snap/blob/516b9bc750f9e66785689940831935691db137dd/snap-adv/word2vec.h#L17)です．
これは，LINEと同じ値にする必要があるので，LINE側を`5`とするのが良さそうです．

---

### 終わりに

このあたりまで書いて気づいたのですが，node2vec論文では，右側の窓幅しか使っていません．
このため，LINEのepoch数をnode2vecの$$k$$倍してるそうです [[^3]]．
C++のコード読んだ感じ両側使ってる気がするのですが，間違っていたら教えてください．

---

[^1]: 去年で少なくともサーベイ論文が3つ
[^2]: [node2vecの該当箇所](https://github.com/snap-stanford/snap/blob/516b9bc750f9e66785689940831935691db137dd/snap-adv/word2vec.cpp#L116)
[^3]: LINEの著者実装にそんなパラメータはないので，`-samples`を`k`倍でしょうか
